{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try encoder-decoder models with attention on German-to-English machine translation problem using Multi30k data.\n",
    "The Multi30k data can be automatically downloaded or we also provide the data in * multi30k_test_purpose* folder. For quick test purpose, you can use *.10de/en dataset, which is part of multi30k_test_purpose data but much more smaller. \n",
    "\n",
    "\n",
    "\n",
    "The pre-processing part (data loading, tokenizing), Encoder part is already implemented. You have to accomplish the part to apply attention mechanism in Decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!conda install -y -c conda-forge spacy  \n",
    "!conda install -y -c pytorch torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Let's first import all the dependencies we will need for this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.de import German\n",
    "import io\n",
    "import random\n",
    "from collections import Counter\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "Collecting en-core-web-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: setuptools in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (61.2.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.22.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.27.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.15)\n",
      "Requirement already satisfied: jinja2 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.3.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "/home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "Collecting de-core-news-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.3.0/de_core_news_sm-3.3.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.6 MB 2.8 MB/s eta 0:00:01��    | 12.5 MB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from de-core-news-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.6.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (21.3)\n",
      "Requirement already satisfied: jinja2 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.22.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: setuptools in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (61.2.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (4.64.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.7.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.27.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (8.0.15)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (4.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.0.12)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.0.1)\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-3.3.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!~/miniconda3/envs/aml_attention_env/bin/python -m spacy download en_core_web_sm\n",
    "!~/miniconda3/envs/aml_attention_env/bin/python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset and making it iterable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import Multi30k\n",
    "\n",
    "# This is needed since original host server keeps shutting down\n",
    "# Update URLs to point to data stored by user\n",
    "Multi30k.urls = [\n",
    "    \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\",\n",
    "    \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\",\n",
    "    \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/mmt_task1_test2016.tar.gz\"\n",
    "]\n",
    "\n",
    "ROOT = './'\n",
    "\n",
    "# After first download, this line can be disabled\n",
    "Multi30k.download(ROOT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/home/lourenco/miniconda3/envs/aml_attention_env/lib/python3.9/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "SRC = Field(tokenize = tokenize_de, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "\n",
    "# partial of multi30k data, only for test purpose during implementation \n",
    "\"\"\"\n",
    "ROOT = './'\n",
    "Multi30k.download(ROOT)\n",
    "\n",
    "train_data, valid_data, test_data = Multi30k.splits(path = ROOT + \"/multi30k_test_purpose/\", exts = ('.10de', '.10en'), \n",
    "                                                    fields = (SRC, TRG))\n",
    "\n",
    "#At the end if you can train and evaluate with whole multi30k data set\n",
    "\"\"\"\n",
    "\n",
    "train_data, valid_data, test_data = Multi30k.splits(path=\"./multi30k\", exts = ('.de', '.en'), \n",
    "                                                    fields = (SRC, TRG))\n",
    "\n",
    "\n",
    "#Building vocabularies, which map string to token_ids and vice versa\n",
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# generate iterator, #\n",
    "#for this exercise we only use train data/train_iterator\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural machine translation with attention "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, emb_dim, encoder_hidden_dim, decoder_hid_dim, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_dim = input_size\n",
    "        self.encoder_hidden_dim = encoder_hidden_dim\n",
    "        self.decoder_hid_dim = decoder_hid_dim\n",
    "       \n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, emb_dim)\n",
    "        \n",
    "        #bidirectional GRU\n",
    "        self.rnn = nn.GRU(emb_dim, encoder_hidden_dim, bidirectional = True)\n",
    "        \n",
    "        self.fc = nn.Linear(encoder_hidden_dim*2,decoder_hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_source):\n",
    "        #Embed input words\n",
    "        embedded = self.dropout(self.embedding(input_source))\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #final hidden state (forwards and backwards) of encode is also initial decoder hidden state\n",
    "        #  encoder RNNs fed through a linear layer\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below, you find the class of Decoder. Accomplish the attention part accordingly.\n",
    " \n",
    "\n",
    "### Reminder:\n",
    "At step $t$, given all hidden states of encoder-rnn and previous hidden state of decoder,\n",
    "\n",
    "* attention weights should be calculated\n",
    "* context vector: weighted sum of weighted sum of the encoder hidden state, which will be given to decoder\n",
    "\n",
    "\n",
    "context vector: $c_t = \\sum_{t=1}^{T} \\alpha (s_{t-1}, h_{t'}) h_{t'}$ \n",
    "\n",
    "\n",
    "attention_weights: \n",
    "\n",
    "$f_{att} (h_{t'}, s_{t-1}) = v_{a}^{\\top} energy$  \n",
    "\n",
    "$energy = tanh (attn[h_{t'}, s_{t-1}])$  \n",
    "where  $v_{a}$ is the learnable parameter. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, decoder_output_dim, emb_dim, encoder_hid_dim, decoder_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.encoder_hid_dim = encoder_hid_dim\n",
    "        self.decoder_hid_dim = decoder_hid_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        self.embedding = nn.Embedding(decoder_output_dim, emb_dim)\n",
    "        \n",
    "        #attention layer\n",
    "        self.attention = nn.Linear((encoder_hid_dim * 2) + decoder_hid_dim, decoder_hid_dim)\n",
    "        self.v = nn.Parameter(torch.rand(decoder_hid_dim))\n",
    "        \n",
    "        self.rnn = nn.GRU((encoder_hid_dim * 2) + emb_dim, decoder_hid_dim)\n",
    "        \n",
    "        self.out = nn.Linear((encoder_hid_dim * 2) + decoder_hid_dim + emb_dim, decoder_output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "       \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "             \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_sen_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        \n",
    "         #------------------Task starts here--------------------\n",
    "        # 1. calculate attention weights: concatenate decoder previous hidden states and encoder_outputs \n",
    "        # and passing them through attention layer and a tanh activation function.\n",
    "         \n",
    "        #encoder hidden states are a sequence of $T$ tensors, \n",
    "        # previous decoder hidden state is a single tensor, so repeat the previous decoder hidden state $T$ times.\n",
    "        \n",
    "        # calculate energy according the formula given above\n",
    "        # energy = ...\n",
    "        \n",
    "        energy = None\n",
    "        \n",
    "        #similar to the variable v in the formular above\n",
    "        #v= ....\n",
    "        v = None\n",
    "        \n",
    "       \n",
    "        \n",
    "        # multiplication of v and energy\n",
    "        # attention = ...\n",
    "        attention = None\n",
    "        \n",
    "        # softmax on the attention \n",
    "        #att = ....\n",
    "        att = None\n",
    "       \n",
    "        # calculate dynamic context vector: weighted sum of the encoder hidden state\n",
    "        \n",
    "        #context_v = ...\n",
    "        context_v = None\n",
    "        \n",
    "        #------------------Task ends here--------------------\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, context_v), dim = 2)\n",
    "        \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        \n",
    "        \n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        context_v = context_v.squeeze(0)\n",
    "        \n",
    "        output = self.out(torch.cat((output, context_v, embedded), dim = 1))\n",
    "        return output, hidden.squeeze(0), att.squeeze(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class builModel(nn.Module):\n",
    "    def __init__(self, encoder, decoder, pad_idx, sos_idx, eos_idx, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.pad_idx = pad_idx\n",
    "        self.sos_idx = sos_idx\n",
    "        self.eos_idx = eos_idx\n",
    "        self.device = device\n",
    "        \n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        if trg is None:\n",
    "            assert teacher_forcing_ratio == 0, \"Must be zero during inference\"\n",
    "            inference = True\n",
    "            #trg tensor filled with <sos> tokens.\n",
    "            trg = torch.zeros((100, src.shape[1])).long().fill_(self.sos_idx).to(src.device)\n",
    "        else:\n",
    "            inference = False\n",
    "            \n",
    "        batch_size = src.shape[1]\n",
    "        max_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.decoder_output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "         #tensor to store attention\n",
    "        attentions = torch.zeros(max_len, batch_size, src.shape[0]).to(self.device)\n",
    "        \n",
    "       #encoder outputs and hidden state\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "                \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        output = trg[0,:]\n",
    "        \n",
    "        for t in range(1, max_len):\n",
    "            # last hidden state of encoder acts as initial hidden state in the decoder. \n",
    "            # In the further steps, all encoder outputs, previous hidden state of decoder and output are inserted into decoder\n",
    "        \n",
    "            output, hidden, attention_score = self.decoder(output, hidden, encoder_outputs)#self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention\n",
    "            outputs[t] = output\n",
    "            attentions[t] = attention_score\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.max(1)[1]\n",
    "            output = (trg[t] if teacher_force else top1)\n",
    "            if inference and output.item() == self.eos_idx:\n",
    "                return outputs[:t], attentions[:t]\n",
    "      \n",
    "        return outputs, attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "DECODER_OUTPUT_DIM = len(TRG.vocab)\n",
    "ENCODER_EMB_DIM = 256\n",
    "DECODER_EMB_DIM = 256\n",
    "ENCODER_HID_DIM = 512\n",
    "DECODER_HID_DIM = 512\n",
    "ENCODER_DROPOUT = 0.5\n",
    "DECODER_DROPOUT = 0.5\n",
    "PAD_IDX = SRC.vocab.stoi['<pad>']\n",
    "SOS_IDX = TRG.vocab.stoi['<sos>']\n",
    "EOS_IDX = TRG.vocab.stoi['<eos>']\n",
    "\n",
    "\n",
    "\n",
    "encoder = Encoder(INPUT_DIM, ENCODER_EMB_DIM, ENCODER_HID_DIM, DECODER_HID_DIM, ENCODER_DROPOUT)\n",
    "decoder = Decoder(DECODER_OUTPUT_DIM, DECODER_EMB_DIM, ENCODER_HID_DIM, DECODER_HID_DIM, DECODER_DROPOUT)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = builModel(encoder, decoder, PAD_IDX, SOS_IDX, EOS_IDX, device).to(device)\n",
    "\n",
    "\n",
    "lr = 0.001\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #model returns attention vectors over the batch of source source sentences\n",
    "        output, attention = model(src, trg)\n",
    "         \n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #Calculate Loss\n",
    "        loss = criterion(output, trg)\n",
    "        ## Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        #Clips gradient norm \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "\n",
    "best_train_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    \n",
    "  \n",
    "    if train_loss < best_train_loss:\n",
    "        best_train_loss = train_loss\n",
    "        torch.save(model.state_dict(), 'exercise4_model.pt')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation results\n",
    "\n",
    "### first load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('exercise4_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly read a line of training/test sentence from train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_i = random.randint(0,len(train_data.examples)-1)\n",
    "random_i = 4\n",
    "src_sentence = ' '.join(vars(train_data.examples[random_i])['src'])\n",
    "trg_reference = ' '.join(vars(train_data.examples[random_i])['trg'])\n",
    "print(f'src = {src_sentence}')\n",
    "print(f'trg = {trg_reference}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## accomplish the function, which gives the tranlation of the given sentence using given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence):\n",
    "    model.eval()\n",
    "    \n",
    "    #first tokenized the sentences\n",
    "    tokenized = tokenize_de(sentence) \n",
    "    #lowercase the tokens and add start/end tokens\n",
    "    tokenized = ['<sos>'] + [t.lower() for t in tokenized] + ['<eos>']\n",
    "    # numericalize tokens by converting them into their indexes using source vocabulary\n",
    "    numericalized = [SRC.vocab.stoi[t] for t in tokenized] \n",
    "    sentence_length = torch.LongTensor([len(numericalized)]).to(device) \n",
    "    #convert the sentence into tensor\n",
    "    tensor = torch.LongTensor(numericalized).unsqueeze(1).to(device) \n",
    "    \n",
    "    #------------------Task begins here--------------------\n",
    "    #----------pass inputs into the model ....\n",
    "    output_tensor_logits, attention= ...\n",
    "    #get highest predicted token index for each element\n",
    "    translation_tensor = ....\n",
    "    #------------------Task ends here--------------------\n",
    "    # convert translation output into string/text\n",
    "    translation = [TRG.vocab.itos[t] for t in translation_tensor]\n",
    "    translation, attention = translation[1:], attention[1:]\n",
    "    return translation, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation, attention = translate_sentence(model, src_sentence)\n",
    "\n",
    "print(src_sentence)\n",
    "print(\"-------------\")\n",
    "print(f'predicted trg = {translation}')\n",
    "print()\n",
    "print(f'reference trg = {trg_reference}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML Attention",
   "language": "python",
   "name": "aml_attention"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
